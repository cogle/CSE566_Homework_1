{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 566S Homework 1\n",
    "## Christopher Ogle\n",
    "___\n",
    "\n",
    "<p>\n",
    "Note: If you click on a graph it will bring up an interactive graph instead of a static one. Make sure to right click\n",
    "and select open in new tab or else it will replace this tab with the graph.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<ul>\n",
    "    <li><h3>Gprof</h3></li>\n",
    "    <ul>\n",
    "        <li>\n",
    "            <p>\n",
    "                Of the three Performance Profilers analyzed in the assignment this profiler \n",
    "                seemed to be the most documented and widely used. As a result getting on of \n",
    "                the advantages of this profiler is that it is slightly easier to get started \n",
    "                with. This is a plus if you are simply trying to quickly profile something as\n",
    "                there is ample documentation and setup is not extremely arduous. \n",
    "            </p>\n",
    "        </li>\n",
    "        <li>\n",
    "            <p>\n",
    "                While simple to use Gprof does have its limitations. One of the most glaring is\n",
    "                its inability to measure the performance of multi-threaded code. When created\n",
    "                multi-core systems were a luxury and thus optimizing over such machines was not \n",
    "                needed; however, in today's world where multi-core machines are the norm \n",
    "                multi-threaded code is no longer a rarity.\n",
    "            </p>\n",
    "        </li>\n",
    "        <li>\n",
    "            <p>\n",
    "                Gprof measures the performance of applications by using a method called\n",
    "                sampling. When sampling the code the it only measures the time when the code\n",
    "                itself is running. Thus if the process is switched out by the CPU it does NOT\n",
    "                measure this time. While this might seem like a benefit it can actually hide\n",
    "                problem areas in our code. Our code might have a bottle neck in an external\n",
    "                library or maybe even in an IO operation. However this problem would never be\n",
    "                realized and while you might spend hours and hours improving your code you would\n",
    "                never realize the problem isn't the code but rather from an external device.\n",
    "                In addition because we are sampling the code there is the possibility that\n",
    "                our code runs so fast that during the sampling time a function never gets\n",
    "                registered as being called, and therefore we might have slightly skewed\n",
    "                results.\n",
    "            </p>\n",
    "        </li>\n",
    "        <li>\n",
    "            <p>\n",
    "               The final issue with Gprof is that optimized code can reek havoc on the\n",
    "               profiling. When compiling with the -O3 flag the compiler will inline\n",
    "               functions. Thus from the view of the profiler functions have disappeared and\n",
    "               no longer will you be able to measure their performance.\n",
    "            </p>\n",
    "        </li>\n",
    "    </ul>\n",
    "    <li><h3>Oprofile</h3></li>\n",
    "    <ul>\n",
    "        <li>\n",
    "            <p>\n",
    "               Like Gprof, Oprofile is a statistical sampling profiler. Oprofile doesn't\n",
    "               just sample only when your process is running, instead it continuously\n",
    "               samples even when your code has stopped running due to a context switch. This\n",
    "               solves one of the problems mention above. The source of a bottleneck might\n",
    "               not be from the code itself, instead it might be from an external library or\n",
    "               poor IO/cache performance. This continuous polling allows problems such as\n",
    "               these to be recognized and dealt with. \n",
    "            </p>\n",
    "        </li>\n",
    "        <li>\n",
    "            <p>\n",
    "               One issue with Oprofile is that the user must run this command as root. While\n",
    "               this is not an issue for somebody using their personal machine. If they are\n",
    "               using a machine where they do not have such privileges then using this tool\n",
    "               may prove to be impossible. Since we are performing a continuous poll and are\n",
    "               root it is now possible to view all processes on the CPU, and thus we now\n",
    "               have the ability to monitor multi-threaded code. While this tool has the\n",
    "               caveat that it must be ran in sudo, it does make itself much more useful by\n",
    "               supporting the profiling of multi-threaded code.\n",
    "            </p>\n",
    "        </li>\n",
    "        <li>\n",
    "            <p>\n",
    "               Unlike Gprof, Oprofile does NOT require recompiling each time you wish to\n",
    "               run a performance test. This means that if I wish to rerun a test I do not\n",
    "               need to recompile the source code in order to generate a new test. This is a\n",
    "               benefit in that source code can sometimes take a pretty long time to build.\n",
    "               At a company I previously interned at I waited on average about 10 minutes \n",
    "               for the companies source code to completely build. Having to do that every \n",
    "               time one wants to measure performance is a costly waste of time. Luckily \n",
    "               Oprofile has no such requirements and does not need to insert itself directly \n",
    "               into the code. \n",
    "            </p>\n",
    "        </li>\n",
    "    </ul>\n",
    "    <li><h3>Perf</h3></li>\n",
    "    <ul>\n",
    "    <li>\n",
    "        <p>\n",
    "               One of the immediate things that I noticed about this profiler is that there\n",
    "               is a lot less information on the web regarding this profiler compared to the\n",
    "               previous two. The Linux man pages contains a large document about\n",
    "               PERF_EVENT_OPEN(2) which is useful, but does require sometime to read and\n",
    "               understand as it aimed towards an advanced level programmer.\n",
    "        </p>\n",
    "    </li>\n",
    "    <li>\n",
    "        <p>\n",
    "               Perf is similar to Oprofile in the sense that it can measure multi-threaded\n",
    "               code, does not need to be compiled with the code in order to run the test and\n",
    "               is a statistical sampling profiler.\n",
    "        </p>\n",
    "    </li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems 2 and 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>Data Collection Methodology</h3></center>\n",
    "<p>\n",
    "An important thing to discuss is how data was collected for the following\n",
    "trials. Every command was ran from the command line, no script was used to gather\n",
    "data. In addition in between each run a tab the Firefox browser was ran for a\n",
    "minute where I visited various sites, in order hopefully clear the cache so\n",
    "that each test would have a similar random starting state. Each level of \n",
    "optimization was ran three times. The output of each test has been stored and\n",
    "is located in the Results folder. The machine used was the campus linux machine.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<center><h3>Gprof Timing Results and Analysis</h3></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "#Times in seconds, pulled from Results folder.\n",
    "y0 = [1.18, 1.18, 1.19]\n",
    "y1 = [1.18, 1.18, 1.23]\n",
    "y2 = [1.19, 1.17, 1.22]\n",
    "\n",
    "#Each Traces represents a level of optimization\n",
    "trace0 = go.Box(\n",
    "    y=y0,\n",
    "    name = 'No Opt'\n",
    ")\n",
    "trace1 = go.Box(\n",
    "    y=y1,\n",
    "    name = 'Level 1 Opt'\n",
    ")\n",
    "trace2 = go.Box(\n",
    "    y=y2,\n",
    "    name = 'Level 2 Opt'\n",
    ")\n",
    "data = [trace0, trace1, trace2]\n",
    "\n",
    "layout=go.Layout(height=750,\n",
    "                 title=\"Gprof: Time to run vs Optimization\", \n",
    "                 xaxis={'title':'Optimization Level'}, \n",
    "                 yaxis={'title':'Time (sec)'})\n",
    "\n",
    "figure=go.Figure(data=data,layout=layout)\n",
    "py.iplot(figure, filename='gprof_graph')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;\">\n",
    "    <a href=\"https://plot.ly/~cogle/10/\" target=\"_blank\"\n",
    "       title=\"Gprof: Time to run vs Optimization\" \n",
    "       style=\"display: block; text-align: center;\">\n",
    "    <img src=\"https://plot.ly/~cogle/10.png\" \n",
    "         alt=\"Gprof: Time to run vs Optimization\" \n",
    "         style=\"max-height:750\",\n",
    "         onerror=\"this.onerror=null;this.src='https://plot.ly/404.png';\" /></a>\n",
    "    <script data-plotly=\"cogle:10\"  src=\"https://plot.ly/embed.js\" async></script>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<center><h3>Gprof Data Analysis</h3></center>\n",
    "\n",
    "<p>\n",
    "The results above for Gprof surprised me a bit. One of the first things that\n",
    "is apparent from this graph is that I was unable to collect data past Level 2\n",
    "Optimization. I was not 100 percent sure as to why this happened but my\n",
    "hypothesis is was follows; -O3 optimization turns on \n",
    "<code>-finline-functions</code>, which is inhibiting Gprof \n",
    "from sticking in its timers. In order to test this idea I \n",
    "copied the original code and changed <code>vm_multiply()</code> to be and \n",
    "inline function and reran the gprof test with no optimization. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/cogle/CSE566_Homework_1/master/Results/gprof/Hypothesis/Hypothesis_snip.PNG?token=AE67yO2TfbhATypt7fkJZhxt01qCSIkdks5XetjnwA%3D%3D\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Sure enough having inlined our function has caused its calls to disappear, \n",
    "yet the time to complete the program is on par with previously ran tests runs. \n",
    "Therefore, I believe that Optimization Level 3's aggressive optimization tactics\n",
    "make it so that Gprof's timing hooks are no longer registered due to the \n",
    "<code>-finline-functions</code> optimization. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<center><h3>Operf Timing Results and Analysis</h3></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "#CPU events registered, pulled from results folder\n",
    "y0 = [15923, 15794, 15692]\n",
    "y1 = [16120, 16428, 16083]\n",
    "y2 = [15723, 16101, 15694]\n",
    "y3 = [15798, 15680, 17318]\n",
    "y4 = [9217, 8964, 8785]\n",
    "\n",
    "#Each Traces represents a level of optimization\n",
    "trace0 = go.Box(\n",
    "    y=y0,\n",
    "    name = 'No Opt'\n",
    ")\n",
    "trace1 = go.Box(\n",
    "    y=y1,\n",
    "    name = 'Level 1 Opt'\n",
    ")\n",
    "trace2 = go.Box(\n",
    "    y=y2,\n",
    "    name = 'Level 2 Opt'\n",
    ")\n",
    "trace3 = go.Box(\n",
    "    y=y3,\n",
    "    name = 'Level 3 Opt'\n",
    ")\n",
    "trace4 = go.Box(\n",
    "    y=y4,\n",
    "    name = 'Level Fast Opt'\n",
    ")\n",
    "data = [trace0, trace1, trace2, trace3,trace4]\n",
    "\n",
    "layout=go.Layout(height=1000,\n",
    "                 title=\"Operf: Number of CPU Events vs Optimization Level\", \n",
    "                 xaxis={'title':'Optimization Level'}, \n",
    "                 yaxis={'dtick': 500,\n",
    "                        'title':'Number of CPU Events'})\n",
    "\n",
    "figure=go.Figure(data=data,layout=layout)\n",
    "py.iplot(figure, filename='operf_graph')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;\">\n",
    "    <a href=\"https://plot.ly/~cogle/12/\" target=\"_blank\" \n",
    "       title=\"Operf: Number of CPU Events vs Optimization Level\" \n",
    "       style=\"display: block; text-align: center;\">\n",
    "    <img src=\"https://plot.ly/~cogle/12.png\" \n",
    "       alt=\"Operf: Number of CPU Events vs Optimization Level\" \n",
    "       style=\"max-height:1000\",\n",
    "       onerror=\"this.onerror=null;this.src='https://plot.ly/404.png';\" /></a>\n",
    "    <script data-plotly=\"cogle:12\"  src=\"https://plot.ly/embed.js\" async></script>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>Operf Data Analysis</h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Using an interrupt polling system allowed us to collect far more data, than\n",
    "inserting timing hooks which is the method that Gprof relies on. One of the\n",
    "trends that is really hard to not notice is that up until performing Fast\n",
    "Optimization each function call generated about the same number of CPU events.\n",
    "I had expected to see a linear trend downward in the number of events because I\n",
    "figured that as the optimizer optimizes that it would get rid of extraneous \n",
    "code. After looking at what exactly each level of optimization does I think that\n",
    "while one might optimize the code it has to be in compliance with C strict\n",
    "standards. However, compiling with Fast Optimization disregards this the \n",
    "compliance mode and optimizes for pure speed.    \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>Perf Timing Results and Analysis</h3></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "#CPU events registered, pulled from results folder\n",
    "y0 = [1.217287294, 1.181955770, 1.183942236]\n",
    "y1 = [1.227768100, 1.198169738, 1.211748535]\n",
    "y2 = [1.196514761, 1.202492659, 1.219955811]\n",
    "y3 = [1.189910993, 1.229740070, 1.303206873]\n",
    "y4 = [0.701674410, 0.708538378, 0.537496915]\n",
    "\n",
    "#Each Traces represents a level of optimization\n",
    "trace0 = go.Box(\n",
    "    y=y0,\n",
    "    name = 'No Opt'\n",
    ")\n",
    "trace1 = go.Box(\n",
    "    y=y1,\n",
    "    name = 'Level 1 Opt'\n",
    ")\n",
    "trace2 = go.Box(\n",
    "    y=y2,\n",
    "    name = 'Level 2 Opt'\n",
    ")\n",
    "trace3 = go.Box(\n",
    "    y=y3,\n",
    "    name = 'Level 3 Opt'\n",
    ")\n",
    "trace4 = go.Box(\n",
    "    y=y4,\n",
    "    name = 'Level Fast Opt'\n",
    ")\n",
    "data = [trace0, trace1, trace2, trace3,trace4]\n",
    "\n",
    "layout=go.Layout(height=750,\n",
    "                 title=\"Perf: Time to run vs Optimization\", \n",
    "                 xaxis={'title':'Optimization Level'}, \n",
    "                 yaxis={'title':'Time (sec)'})\n",
    "\n",
    "figure=go.Figure(data=data,layout=layout)\n",
    "py.iplot(figure, filename='perf_graph')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;\">\n",
    "    <a href=\"https://plot.ly/~cogle/18/\" target=\"_blank\" \n",
    "       title=\"Perf: Time to run vs Optimization\" style=\"display: block; text-align: center;\">\n",
    "        <img src=\"https://plot.ly/~cogle/18.png\" alt=\"Perf: Time to run vs Optimization\" \n",
    "             style=\"max-height: 1000\" \n",
    "             onerror=\"this.onerror=null;this.src='https://plot.ly/404.png';\" /></a>\n",
    "    <script data-plotly=\"cogle:18\"  src=\"https://plot.ly/embed.js\" async></script>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>Perf Data Analysis</h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Similar to the results from the Operf we see that we never achieve a\n",
    "significant drop in running time until running our code in Fast Optimization\n",
    "mode. This profiler, like Operf, uses an interrupt polling system in order to\n",
    "obtain its results, and again we see that unlike the problems we had with Gprof\n",
    "we were able to collect data for every level of tested optimization. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>Problem 2 Answer</h3></center>\n",
    "<p>\n",
    "The above graphs highlight one of the problems with Gprof's manual insertion of\n",
    "timing hooks. The insertion of timing hooks is highly dependent on the manner in\n",
    "which the code is structured, altering this structure altering this structure\n",
    "renders Gprof clueless as to what is going on. Thus as we increased the\n",
    "optimization levels and more aggressive code restructuring occurred Gprof was\n",
    "unable to measure any events. On the contrary with the interrupt polling that\n",
    "Operf and Perf employ, we are able to monitor the function the entire time\n",
    "regardless of the Optimization level. However, as we increase the Optimization\n",
    "due to what I assume is the inlining of functions we lose granularity with\n",
    "respect to which functions are being called as functions become inlined\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>Problem 4 Answer</h3></center>\n",
    "<p>\n",
    "One of the more startling results to come out of the above graphs is that the\n",
    "Level of Optimization does not appear to decrease the amount of time or cycles\n",
    "that the program takes, unless we compile with the Fast option. This result is\n",
    "particularly surprising as I would have anticipated that there would have been\n",
    "a slight decrease, but on the contrary it appears going from no optimization at\n",
    "all to Level 3 Optimization actually seems to increase the time that it takes or\n",
    "remain about the same. I will admit that my sampling is rather low and that in\n",
    "order to make a much more definitive conclusion I would need to perform a much\n",
    "more extensive sampling of each profiler. As for why this occurs I can not\n",
    "really say. One reason that compiling with Optimization Level Fast is so much\n",
    "faster is that it disregards the strict compliance standards. This however does\n",
    "not explain why there is not a decreasing trend with respect to time/cycles over\n",
    "optimization level.  \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.tools import FigureFactory as FF \n",
    "\n",
    "# Create random data with numpy\n",
    "import numpy as np\n",
    "\n",
    "x = ['No Optimization', 'Level 1 Optimization', \n",
    "     'Level 2 Optimization', 'Level 3 Optimization',\n",
    "     'Level Fast Optimization']\n",
    "\n",
    "reg_no_opt = [15923,15794,15692,16197,16335]\n",
    "rev_no_opt = [15771,16647,16523,16636,16117]\n",
    "\n",
    "reg_opt_1 = [16120,16428,16083,16246,16456]\n",
    "rev_opt_1 = [16617,15634,15717,16690,15818]\n",
    "\n",
    "reg_opt_2 = [15723,16101,15694,16102,16235]\n",
    "rev_opt_2 = [16413,15824,15831,15949,16295]\n",
    "\n",
    "reg_opt_3 = [15798,15680,17318,18178,16442]\n",
    "rev_opt_3 = [16412,15914,15527,15898,16140]\n",
    "\n",
    "reg_opt_fast = [9217,8964,8785,9185,8846]\n",
    "rev_opt_fast = [9272,9162,9114,9271,8846]\n",
    "\n",
    "y0 = [np.average(reg_no_opt),\n",
    "      np.average(reg_opt_1),\n",
    "      np.average(reg_opt_2),\n",
    "      np.average(reg_opt_3),\n",
    "      np.average(reg_opt_fast)]\n",
    "\n",
    "y1 = [np.average(rev_no_opt),\n",
    "      np.average(rev_opt_1),\n",
    "      np.average(rev_opt_2),\n",
    "      np.average(rev_opt_3),\n",
    "      np.average(rev_opt_fast)]\n",
    "\n",
    "# Create traces\n",
    "trace0 = go.Scatter(\n",
    "    x = x,\n",
    "    y = y0,\n",
    "    mode = 'lines+markers',\n",
    "    name = 'r = vM (Default)',\n",
    "    error_y=dict(\n",
    "        type='data',\n",
    "        array=[np.std(reg_no_opt), \n",
    "               np.std(reg_opt_1),\n",
    "               np.std(reg_opt_2),\n",
    "               np.std(reg_opt_3),\n",
    "               np.std(reg_opt_fast)],\n",
    "        visible=True\n",
    "    )\n",
    ")\n",
    "trace1 = go.Scatter(\n",
    "    x = x,\n",
    "    y = y1,\n",
    "    mode = 'lines+markers',\n",
    "    name = 'r = Mv (Reversed)',\n",
    "    error_y=dict(\n",
    "    type='data',\n",
    "        array=[np.std(rev_no_opt), \n",
    "               np.std(rev_opt_1),\n",
    "               np.std(rev_opt_2),\n",
    "               np.std(rev_opt_3),\n",
    "               np.std(rev_opt_fast)],\n",
    "        visible=True\n",
    "    )\n",
    ")\n",
    "data = [trace0, trace1]\n",
    "layout=go.Layout(height=1000,\n",
    "                 title=\"Operf: Number of CPU Events vs Optimization Level\", \n",
    "                 xaxis={'title':'Optimization Level'}, \n",
    "                 yaxis={'dtick': 500,\n",
    "                        'title':'Number of CPU Events'})\n",
    "\n",
    "figure=go.Figure(data=data,layout=layout)\n",
    "py.iplot(figure, filename='reverse-comparision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;\">\n",
    "    <a href=\"https://plot.ly/~cogle/14/\" target=\"_blank\" title=\"Operf: Number of CPU Events vs Optimization Level\"    \n",
    "       style=\"display: block; text-align: center;\"><img src=\"https://plot.ly/~cogle/14.png\" \n",
    "       alt=\"Operf: Number of CPU Events vs Optimization Level\" style=\"max-height:1000\"\n",
    "       onerror=\"this.onerror=null;this.src='https://plot.ly/404.png';\" /></a>\n",
    "    <script data-plotly=\"cogle:14\"  src=\"https://plot.ly/embed.js\" async></script>\n",
    "</div>\n",
    "<div style=\"max-width:100%;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "from plotly.tools import FigureFactory as FF \n",
    "\n",
    "reg_no_opt = [15923,15794,15692,16197,16335]\n",
    "rev_no_opt = [15771,16647,16523,16636,16117]\n",
    "\n",
    "reg_opt_1 = [16120,16428,16083,16246,16456]\n",
    "rev_opt_1 = [16617,15634,15717,16690,15818]\n",
    "\n",
    "reg_opt_2 = [15723,16101,15694,16102,16235]\n",
    "rev_opt_2 = [16413,15824,15831,15949,16295]\n",
    "\n",
    "reg_opt_3 = [15798,15680,17318,18178,16442]\n",
    "rev_opt_3 = [16412,15914,15527,15898,16140]\n",
    "\n",
    "reg_opt_fast = [9217,8964,8785,9185,8846]\n",
    "rev_opt_fast = [9272,9162,9114,9271,8846]\n",
    "\n",
    "\n",
    "\n",
    "data_matrix = [['Run + Optimization Level', 'Average', 'Standard Deviation'],\n",
    "               ['Default No Opt', np.average(reg_no_opt), np.std(reg_no_opt)],\n",
    "               ['Reverse No Opt', np.average(rev_no_opt), np.std(rev_no_opt)],\n",
    "               ['Default Opt Level 1', np.average(reg_opt_1), np.std(reg_opt_1)  ],\n",
    "               ['Reverse Opt Level 1', np.average(rev_opt_1), np.std(rev_opt_1)  ],\n",
    "               ['Default Opt Level 2', np.average(reg_opt_2), np.std(reg_opt_2)  ],\n",
    "               ['Reverse Opt Level 2', np.average(rev_opt_2), np.std(rev_opt_2)  ],\n",
    "               ['Default Opt Level 3', np.average(reg_opt_3), np.std(reg_opt_3)  ],\n",
    "               ['Reverse Opt Level 3', np.average(rev_opt_3), np.std(rev_opt_3)  ],\n",
    "               ['Default Opt Fast', np.average(reg_opt_fast), np.std(reg_opt_fast)],\n",
    "               ['Reverse Opt Fast', np.average(rev_opt_fast), np.std(rev_opt_fast)]]\n",
    "\n",
    "table = FF.create_table(data_matrix)\n",
    "py.iplot(table, filename='results_table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"width:100%\">\n",
    "<a href=\"https://plot.ly/~cogle/16/\" target=\"_blank\" title=\"\" \n",
    "   style=\"display: block; text-align: center;\">\n",
    "<img src=\"https://plot.ly/~cogle/16.png\" alt=\"\" \n",
    "     style=\"max-height: 100%;width: 600px;\"  width=\"600\"      \n",
    "     onerror=\"this.onerror=null;this.src='https://plot.ly/404.png';\" /></a>\n",
    "    <script data-plotly=\"cogle:16\"  src=\"https://plot.ly/embed.js\" async></script>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>Data Analysis and Conclusion</h3></center>\n",
    "<p>\n",
    "Above is the data collected for Problem 5. In this problem I measured  the number \n",
    "of CPU events for a given optimization level 5 times. From the graph above it is \n",
    "clear that there is no definitive answer as to whether or not switching around \n",
    "the order of multiplication speeds up or slows down the code. The graph clearly \n",
    "shows the <b>Default</b> and <b>Reversed</b> lines crossing throughout the \n",
    "experiment with neither line remaining above or below the other line. In addition \n",
    "for every optimization level their exist regions of overlap when both of line's \n",
    "standard deviations are taken into consideration. This points to a an experiment \n",
    "that yielded similar values despite the order of multiplication. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "For this problem we are asked to look at the organization of the cache. One way\n",
    "in which we can do this is by analyzing the Perf outputs. Perf contains a large\n",
    "number of events that a user can track, amongst these trackable events are\n",
    "cache-related events. This allows us the ability to analyze how the cache is\n",
    "being used by our program. Somethings I noticed was that our program relies\n",
    "very heavily on the L1 cache. The number of loads and evictions from this\n",
    "particular cache far outnumber the other cache. One thing that this points to\n",
    "is its importance. Now one reason that the number of the cache loads might be\n",
    "so large is that typically the size of this cache is much smaller. This is due\n",
    "to cost associated with this cache. Thus I would anticipate a larger number of\n",
    "loads, as is seen. The other cache received less load request but it is likely\n",
    "that the amount of data stored in this particular level is far greater than that\n",
    "of the L1. \n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
